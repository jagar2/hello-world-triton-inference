{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Final_Exam.ipynb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# ⌛️ Final Exam\n",
    "\n",
    "This Final Exam is designed to test your mastery of the Python programming language. You will be asked to respond to a series of questions both multiple choice and short answer problems using python.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* You are allowed to use anything in jupyterlab to help you solve the problems. \n",
    "* You cannot open any other jupyter notebooks during the exam.\n",
    "* You are not allowed to open any additional files. \n",
    "* You must run all code and press the submit button when shown to record your grades. If you do not do this your scores might not be recorded. \n",
    "* All of your responses should be persistent if you restart the kernel, however entries can only be updated if you run the cell and hit submit. \n",
    "\n",
    "**The exam is out of 238 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part 1: Entering Your Information for Credit\n",
    "\n",
    "To receive credit for assignments, it is important we can identify your work from others. To do this, we will ask you to enter your information in the following code block.\n",
    "\n",
    "You must hit submit and see the message saying the data is saved. If you do not see this message contact your instructor to ensure you are getting credit for your work.\n",
    "\n",
    "**Note: do not delete the output.log file or the .responses.json file or you might lose your current work.**\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "1. Run the block of code at the top of the notebook that imports and sets up the autograder. This will allow you to check your work. \n",
    "2. Run the block of code below to ensure your packages are up to date\n",
    "\n",
    "All of the grader tests check to ensure your information is saved and accessible by the grader. If you see an error stating that your information is not found please restart the kernel and enter your student information again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "from subprocess import call\n",
    "import sys\n",
    "\n",
    "package_name = 'ENGR131_Util_2024'\n",
    "version = '1.0.13'\n",
    "package_version = f'{package_name}=={version}'\n",
    "\n",
    "try:\n",
    "    # Check if the package and version are installed\n",
    "    pkg_resources.require(package_version)\n",
    "    print(f'{package_version} is already installed.')\n",
    "except pkg_resources.DistributionNotFound:\n",
    "    # If not installed, install the package\n",
    "    print(f'{package_version} not found. Installing...')\n",
    "    call([sys.executable, '-m', 'pip', 'install', package_version])\n",
    "except pkg_resources.VersionConflict:\n",
    "    # If a different version is installed, you can choose to upgrade/downgrade\n",
    "    installed_packages = {dist.key: dist.version for dist in pkg_resources.working_set}\n",
    "    installed_version = installed_packages.get(package_name.lower())\n",
    "    print(f'{package_name} {installed_version} is installed, but {version} is required.')\n",
    "    # Optionally, upgrade or downgrade the package to the required version\n",
    "    call([sys.executable, '-m', 'pip', 'install', '--upgrade', package_version])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import responses, StudentInfoForm, cell_logger\n",
    "from ENGR131_Util_2024 import submit_question, ResponseStore, ValidateLogFile\n",
    "\n",
    "\n",
    "# Register the log function to be called before any cell is executed\n",
    "get_ipython().events.register('pre_run_cell', cell_logger)\n",
    "responses[\"assignment\"] = \"final_1\"\n",
    "\n",
    "StudentInfoForm(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1: Match the Correct Definition**\n",
    "\n",
    "*18 points*\n",
    "\n",
    "Please run the block of code below, and respond to the prompts with the most suitable response. \n",
    "\n",
    "Make sure you hit the submit button or your grade will not be recorded. Confirmation that your responses are recorded will appear below the code block. We will only grade your most recent set of responses. You can submit entries as many times as you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import responses\n",
    "from ENGR131_Util_2024 import TypesQuestion_f2024 as TypesQuestion\n",
    "\n",
    "TypesQuestion(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Question 2: Select the option that matches the definition** \n",
    "\n",
    "*8 points*\n",
    "\n",
    "Please run the block of code below, and respond to the prompts with the most suitable response. \n",
    "\n",
    "Make sure you hit the submit button or your grade will not be recorded. Confirmation that your responses are recorded will appear below the code block. We will only grade your most recent set of responses. You can submit entries as many times as you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import MCQQuestion_f2024 as MCQQuestion\n",
    "from ENGR131_Util_2024 import responses\n",
    "\n",
    "MCQQuestion(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3: Select all statements which are TRUE** \n",
    "\n",
    "*20 points*\n",
    "\n",
    "Please run the block of code below, and respond to the prompts with the most suitable response. \n",
    "\n",
    "Make sure you hit the submit button or your grade will not be recorded. Confirmation that your responses are recorded will appear below the code block. We will only grade your most recent set of responses. You can submit entries as many times as you like. \n",
    "\n",
    "**Note** If text is not fully rendered (e.g, you see at the end of the sentance ...) zoom out with control/cmd + -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import responses\n",
    "from ENGR131_Util_2024 import SelectMany_f2024 as SelectMany\n",
    "\n",
    "\n",
    "out = SelectMany(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4: Reading and Interpreting Python Code** \n",
    "\n",
    "*45 points*\n",
    "\n",
    "You are provided with the following code:\n",
    "\n",
    "```python\n",
    "1 numbers = [5, 4.0]\n",
    "2 total = 0\n",
    "3 \n",
    "4 for num in numbers:\n",
    "5    while total < 9:\n",
    "6       total += num + 1.0\n",
    "7    break\n",
    "```\n",
    "\n",
    "Please run the block of code below and respond to the prompts with the most suitable response. \n",
    "\n",
    "Make sure you hit the submit button or your grade will not be recorded. Confirmation that your responses are recorded will appear below the code block. We will only grade your most recent set of responses. You can submit entries as many times as you like. \n",
    "\n",
    "1. You will be asked to select the most relevant comment for the lines of code selected. \n",
    "2. You will be asked to describe how the code is executed. Please use the debugger tool to help ensure you have a correct answer.\n",
    "\n",
    "   1. Line number: This is the line number of the code that is run during the execution of the code.\n",
    "   2. Variable Changed: This is the variable whose value is changed during the execution of the code. \n",
    "\n",
    "      **Note** if no variable is changed - such as when evaluating logical expressions, select \"None\".\n",
    "   3. Current Value: This is the value of the variable after the line of code is executed. \n",
    "      * If a logical expression is evaluated, please enter the value of the logical expression. \n",
    "      * If a control statement is run enter N/A.\n",
    "   4. DataType: This is the data type of the variable after the line of code is executed. \n",
    "      * If a logical expression is evaluated, please enter the data type of the logical expression. \n",
    "      * If a control statement is run enter N/A. \n",
    "   \n",
    "      **Note**: The autograder has mechanisms to provide partial credit. If you skip a step, it will continue grading at the next correct step. \n",
    "\n",
    "We provide the code in Python for your convenience. Do not alter the code to avoid responding incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "numbers = [5, 4.0]\n",
    "total = 0\n",
    "\n",
    "for num in numbers:\n",
    "   while total < 9:\n",
    "      total += num + 1.0\n",
    "   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import ReadingPythonQuestion_f2024 as ReadingPythonQuestion\n",
    "from ENGR131_Util_2024 import responses\n",
    "\n",
    "ReadingPythonQuestion(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results saved. This can take a minute to run.\n",
    "\n",
    "You can interrupt this execution by pressing the stop button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 5: Using Data Types \n",
    "\n",
    "*30 Points*\n",
    "\n",
    "We have written a function that converts a DataType. Pass values with the expected DataTypes as defined below to the `convert_to_string` function. The function will print the output.\n",
    "\n",
    "0. Run the `convert_to_string` function first.\n",
    "1. Pass an integer `57` to `convert_to_string`.\n",
    "    - Save the output to a variable `int_`.\n",
    "2. Pass a float `6.28318` to `convert_to_string`.\n",
    "    - Save the output to a variable `float_`.\n",
    "3. Pass a boolean with a false value to `convert_to_string`.\n",
    "    - Save the output to a variable `bool_`.\n",
    "4. Pass a string `Python is fun` to `convert_to_string`.\n",
    "    - Save the output to a variable `string_`.\n",
    "5. Pass a list of integers `4`, `5`, `6` to `convert_to_string`.\n",
    "    - Save the output to a variable `list_`.\n",
    "6. Pass a tuple of strings `\"d\"`, `\"e\"`, `\"f\"` to `convert_to_string`.\n",
    "    - Save the output to a variable `tuple_`.\n",
    "7. Pass a dictionary with a key `color` and a value `blue` as a string and a key `number` and a value `8` as an integer to `convert_to_string`.\n",
    "    - Save the output to a variable `dict_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_string(data):\n",
    "    if isinstance(data, int):\n",
    "        print(data)\n",
    "    elif isinstance(data, float):\n",
    "        print(\"{:.2f}\".format(data))\n",
    "    elif isinstance(data, bool):\n",
    "        print(str(data))\n",
    "    elif isinstance(data, str):\n",
    "        print(data)\n",
    "    elif isinstance(data, list):\n",
    "        elements = \", \".join([str(x) for x in data])\n",
    "        print(elements)\n",
    "    elif isinstance(data, tuple):\n",
    "        elements = \", \".join([str(x) for x in data])\n",
    "        print(elements)\n",
    "    elif isinstance(data, dict):\n",
    "        pairs = \", \".join(\n",
    "            [\"Key = \" + str(k) + \" Value = \" + str(v) for k, v in data.items()]\n",
    "        )\n",
    "        print(pairs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Pass an integer `57` to `convert_to_string`. \n",
    "# Save the output to a variable `int_`.\n",
    "# completion of this step will pass test 1\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Pass an float `6.28318` to `convert_to_string`. \n",
    "# Save the output to a variable `float_`.\n",
    "# completion of this step will pass test 2\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Pass a boolean with a false value to `convert_to_string`. \n",
    "# Save the output to a variable `bool_`.\n",
    "# completion of this step will pass test 3\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Pass an string `Python is fun` to `convert_to_string`. \n",
    "# Save the output to a variable `string_`.\n",
    "# completion of this step will pass test 4\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Pass a list of integers `4`, `5`, `6` to `convert_to_string`. \n",
    "# Save the output to a variable `list_`.\n",
    "# completion of this step will pass test 5\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Pass a tuple of strings \"d\", \"e\", \"f\" to `convert_to_string`. \n",
    "# Save the output to a variable `tuple_`.\n",
    "# completion of this step will pass test 6\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7. Pass a dictionary with a key `color` and a value `blue` as a string and a key `number` and a value `8` as an integer to `convert_to_string`. \n",
    "# Save the output to a variable `dict_`.\n",
    "# completion of this step will pass test 7\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5 - Exploring DataTypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results saved. This can take a minute to run.\n",
    "\n",
    "You can interrupt this execution by pressing the stop button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 6: Building a Stress Sensor\n",
    "\n",
    "*36 Points*\n",
    "\n",
    "In mechanical engineering, it is common to monitor the stress experienced by materials under load. We will build a class to implement a stress sensor. This sensor will save and also set a stress value in Pascals. Additionally, the class will convert the stress value given in Pascals to pounds per square inch (PSI).\n",
    "\n",
    "1. Build a class called `StressSensor`. This class will have an initialization method and two additional methods.\n",
    "    - Add an initialization method that accepts an initial stress value in Pascals as a variable `stress`.\n",
    "      - Save the `stress` as an object attribute `stress_pa`. This is the stress in Pa.\n",
    "\n",
    "    - Build a method `set_stress` that will set the object attribute `stress_pa`.\n",
    "      - This method takes one input `stress`.\n",
    "      - We want to make sure the input is a number. Do this by **trying** to convert it to a `float` using the built-in `float` method.\n",
    "        - If `stress` is a number that can be converted to a float, save it to the object attribute `stress_pa`.\n",
    "       - If `stress` cannot be converted to a float, set the object attribute `stress_pa` to the string 'fail'.\n",
    "\n",
    "    - Build a method `to_psi` that converts the stress from Pascals to pounds per square inch.\n",
    "      - Convert the stress using the following equation.\n",
    "        $$PSI = Pascals \\times 0.000145038$$\n",
    "      - Return the stress in PSI.  \n",
    "\n",
    "2. Instantiate a `StressSensor` `material_sensor` with an initial `stress` of `85000` Pa.\n",
    "   \n",
    "3. Extract the stress in Pa from the object `material_sensor`.\n",
    "    - Assign the output to a variable `stress_pa`.\n",
    "\n",
    "4. Extract the stress in PSI from the object `material_sensor`.\n",
    "    - Assign the output to a variable `stress_psi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your class for StressSensor goes here\n",
    "...\n",
    "\n",
    "# Instantiate the StressSensor material_sensor here\n",
    "...\n",
    "\n",
    "# extract the stress in Pascals\n",
    "...\n",
    "\n",
    "# extract the stress in pounds per square inch\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6-Building a Stress Sensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results saved. This can take a minute to run.\n",
    "\n",
    "You can interrupt this execution by pressing the stop button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 7: Determining a Price for Structural Beams \n",
    "\n",
    "*40 Points*\n",
    "\n",
    "As a structural engineer, you might want to estimate the total price at which you would sell a set of structural beams you've designed based on the cost of materials from a supplier and a desired profit margin. We will write a Python function to assist you in this task.\n",
    "\n",
    "We have provided you with two dictionaries, `material_cost` and `beam_requirements`. `material_cost` defines the costs of materials from the supplier, and `beam_requirements` defines the materials needed to construct the structural beams. The structure includes two `Custom Alloy Beams`, which are not available from the supplier, that each costs $1200.\n",
    "\n",
    "*Cost of Materials from Supplier*\n",
    "\n",
    "| Material Name (Key) | Cost per Unit (value, in $) |\n",
    "| -------------------- | --------------------------- |\n",
    "| Steel Beam  | 250                           |\n",
    "| Aluminum Beam | 150                          |\n",
    "| Reinforcement Bar   | 50                         |\n",
    "| Concrete Mix  | 120                          |\n",
    "\n",
    "*Materials Required for Building the Structural Beams*\n",
    "\n",
    "| Material Name (Key)       | Quantity (sub-key) | Cost to Build (value, in $)|\n",
    "| ---------------------- | --------------- | --------------------------- |\n",
    "| Steel Beam             | 10              | N/A                         |\n",
    "| Concrete Mix           | 3               | N/A                         |\n",
    "| Reinforcement Bar      | 7               | N/A                         |\n",
    "| Custom Alloy Beam      | 2               | 1200                        |\n",
    "\n",
    "1. Import the package `numpy` as `np`.\n",
    "2. Define a function `price_calculator` that accepts three inputs: `material_cost`, `beam_requirements`, and `profit`.\n",
    "    - Initialize a variable `cost_of_materials`, and set it equal to 0.\n",
    "    - Using a loop, compute the total `cost_of_materials`.\n",
    "        - For standard materials, fetch the cost per unit from `material_cost`.\n",
    "        - For custom components like `Custom Alloy Beam`, use the cost specified in `beam_requirements`.\n",
    "    - Determine the `sales_price` by applying the profit margin to the `cost_of_materials`.\n",
    "        - $$sales\\_price = cost\\_of\\_materials \\times (1 + profit)$$\n",
    "        - Round the final sales price to 2 decimal places using `np.round`.\n",
    "    - Call the provided `print_total` function to get a string to print.\n",
    "    - Print and return the final `sales_price`. \n",
    "3. Call the function `price_calculator` with the appropriate inputs and save the output to a variable `total_price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your import statement goes here.\n",
    "...\n",
    "\n",
    "material_cost = {\n",
    "    \"Steel Beam\": 250,\n",
    "    \"Aluminum Beam\": 150,\n",
    "    \"Reinforcement Bar\": 50,\n",
    "    \"Concrete Mix\": 120,\n",
    "}\n",
    "\n",
    "beam_requirements = {\n",
    "    \"Steel Beam\": {\"quantity\": 10},\n",
    "    \"Concrete Mix\": {\"quantity\": 3},\n",
    "    \"Reinforcement Bar\": {\"quantity\": 7},\n",
    "    \"Custom Alloy Beam\": {\"quantity\": 2, \"price\": 1200},\n",
    "}\n",
    "\n",
    "# profit assignment goes here, we have set this to 63%\n",
    "profit = 0.63\n",
    "\n",
    "# We have provided you with a function to print the total cost of the order\n",
    "# you need to call this function but do not need to change it.\n",
    "def print_total(sales_price):\n",
    "    return f\"Total cost of the order: ${sales_price}\"\n",
    "\n",
    "# Your function price_calculator goes here\n",
    "# Completion of this step should pass test 3\n",
    "...\n",
    "\n",
    "# Your call of the function price_calculator goes here\n",
    "# Completion of this step should pass all tests\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7-Determining a Price of a Structural Beam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results saved. This can take a minute to run.\n",
    "\n",
    "You can interrupt this execution by pressing the stop button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 8: Plotting and Fitting (41 Points):\n",
    "\n",
    "A prevalent task in engineering involves fitting data to a specific model. This exercise will focus on generating noisy data influenced by a sinusoidal function, a fundamental pattern observed in many engineering and physical phenomena. We will plot this data and perform a fitting procedure to align it with our sinusoidal model.\n",
    "\n",
    "1. Begin by importing the necessary libraries. If you've already imported these in a previous part of your work, you might not need to repeat this step; however, it's generally a good practice to ensure all required packages are available.\n",
    "\n",
    "   - Import `numpy` and alias it as `np`.\n",
    "   - Import the `pyplot` module from `matplotlib`, aliasing it as `plt`.\n",
    "   - Import the `curve_fit` function from `scipy.optimize`.\n",
    "\n",
    "2. Define a function `sinusoidal` to calculate and return the values of a sinusoidal function based on the equation:\n",
    "   $$A \\sin(Bx + C)$$\n",
    "   - This function should accept inputs `x`, `A`, `B`, and `C`.\n",
    "\n",
    "3. Utilize the `linspace` function in `numpy` to generate a sequence from $-\\pi$ to $\\pi$ comprising `100` steps. \n",
    "   - Assign this sequence to the variable `x_data`.\n",
    "\n",
    "4. Apply the `sinusoidal` function over `x_data` to calculate the true values when `A` is `2.5`, `B` is `1.2`, and `C` is `0.5`. \n",
    "   - Store these true values in `y_true`.\n",
    "\n",
    "5. Generate noisy data by adding Gaussian-distributed noise to `y_true` using the `random.normal` method in `numpy`. \n",
    "   - Ensure the noise is of the same dimension as `x_data`. \n",
    "   - Scale the noise by `0.2` before adding it to `y_true`, and save the resultant noisy data in `y_noisy`.\n",
    "   - **Hint** you can view the docstring by running `??np.random.normal`\n",
    "\n",
    "6. Plot the noisy data (`x_data` vs `y_noisy`) using the `scatter` function from `matplotlib.pyplot`. \n",
    "   - Label the plot as \"Noisy Data\". \n",
    "   - Assign this plot to `plot_1`.\n",
    "\n",
    "7. Employ the `curve_fit` function to align the noisy data with the `sinusoidal` function across the `x_data` range. \n",
    "   - Store the optimal fitting parameters in `popt` and the covariance of the parameters in `pcov`. \n",
    "     - **Avoid providing any initial guess** or use `None` to ensure compatibility with automatic grading systems.\n",
    "\n",
    "8. Compute the fitted curve using the `sinusoidal` function with the optimal parameters found in the previous step. \n",
    "   - The unpacking operator (`*`) can be used to apply the list of fitted parameters directly. \n",
    "   - Save this fitted curve data in `y_fit`.\n",
    "\n",
    "9. Plot the fitting results (`x_data` vs `y_fit`) using the `plot` function in `pyplot`, setting the line color to green with the `g` marker.\n",
    "    - Label this plot as \"Fitted Sinusoidal\". \n",
    "    - Store this plot as `plot_2`.\n",
    "\n",
    "10. Set the `xlabel` and `ylabel` of the plot to `x` and `y`, respectively, using the appropriate `plt` methods.\n",
    "\n",
    "11. Finally, add a legend to the plot with the `legend` method in `plt` to distinguish between the noisy data and the fitted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Add your import statements here. \n",
    "# Completion of this step will pass the first test\n",
    "...\n",
    "\n",
    "# do not delete the line of code below, it will cause problems with the autograder.\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2. Define the Sinusoidal function.\n",
    "# completion of this step will pass test 2.\n",
    "...\n",
    "\n",
    "# 3. Define your x_data vector\n",
    "# completion of this step will pass test 3.\n",
    "...\n",
    "\n",
    "# 4. Call the sinusoidal function as described above\n",
    "# save the output to the variable y_true\n",
    "# completion of this step will pass test 4.\n",
    "...\n",
    "\n",
    "# 5. Generate the noisy data described above\n",
    "# save the output to the variable y_noisy\n",
    "# completion of this step will pass test 5.\n",
    "# use the ?? module to view the docstring.\n",
    "...\n",
    "\n",
    "# 6. Plot the noisy data using a scatterplot\n",
    "# make sure to add the label \"Noisy Data\"\n",
    "# save the output to the variable plot_1\n",
    "...\n",
    "\n",
    "# 7. Fit the noisy data to the sinusoidal function using curve_fit\n",
    "# save the outputs to the variables popt and pcov\n",
    "# completion of this step will pass test 6.\n",
    "...\n",
    "\n",
    "# 8. Calculate the fitted curve using the sinusoidal function\n",
    "# save the output to the variable y_fit\n",
    "# completion of this step will pass test 7. \n",
    "...\n",
    "\n",
    "# 9. Plot the fitted results as described in the instructions\n",
    "# save the output to the variable plot_2\n",
    "# make sure to add the label \"Fitted Sinusoidal\"\n",
    "...\n",
    "\n",
    "# 10. Add axis labels to the plot\n",
    "# completion of this step will pass a test.\n",
    "...\n",
    "\n",
    "# 11. Add a legend to the plot\n",
    "# completion of this step will pass all tests.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8-Plotting and Fitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results saved. This can take a minute to run.\n",
    "\n",
    "You can interrupt this execution by pressing the stop button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Validating your log file\n",
    "\n",
    "Before your submit your results we would recommend running the following command to validate your log file. This will ensure that you have followed the correct format and that your log file is valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore",
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "ValidateLogFile(\"./output.log\", responses[\"assignment\"], 4, question_max_scores={1: 18, 2: 8, 3: 20, 4:45, 5: 30, 6: 36, 7: 40, 8: 41})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submitting Your Assignment\n",
    "\n",
    "To submit your assignment please use the following link the assignment on GitHub classroom.\n",
    "   \n",
    "Use this [link](https://classroom.github.com/a/-WUNDMbG) to navigate to the assignment on GitHub classroom.\n",
    "\n",
    "**Please submit just your output.log file. No other files are needed.**\n",
    "\n",
    "\n",
    "If you need further instructions on submitting your assignment, please ask your TA during lab. \n",
    "\n",
    "## Viewing your score\n",
    "\n",
    "Each `log` file you have uploaded will have a file with the name of your file + `Grade_Report.md`. You can view this file by clicking on the file name. This will show you the results of the autograder. \n",
    "\n",
    "**Make sure you run your code, and run the tests. If you do not run the test you will not get credit for your work.**\n",
    "\n",
    "```{note}\n",
    "In python and particularly jupyter notebooks it is common that during testing you run cells in a different order, or run cells and modify them. This can cause there to be local variables needed for your solution that would not be recreated on running your code again from scratch. Your assignment will be graded based on running your code from scratch. This means before you submit your assignment you should restart the kernel and run all cells. You can do this by clicking `Kernel` and selecting `Restart and Run All`. If you code does not run as expected after restarting the kernel and running all cells it means you have an error in your code. \n",
    "```\n",
    "\n",
    "## Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q5 - Exploring DataTypes": {
     "name": "q5 - Exploring DataTypes",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> points_ = [3, 3, 3, 3, 6, 6, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q5_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_1'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6L-pDv5p5hDbvPowuS3KmnJvavbodPIc6Rv2MYr6UaSty95p2RUWtzhd0Uta8PZVymdB7qFcP-1Ff4JgWgc_9FKP4w==')\n>>> if str(int_) == out and isinstance(int_, int):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': int_}\n>>> responder.add_response(response)\n>>> assert isinstance(int_, int)\n>>> assert str(int_) == out, 'int_ incorrectly implemented.'\n",
         "failure_message": "int_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "int_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_2'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6L_-fuzaC571cBwKwRoYf4-E3ZG8cXgWTrvThoyyMa59OYClsYkyqt77aXm9s_BtEpbV-Ag85aWIGic6Dcn8TAlo2A==')\n>>> if str(float_) == out and isinstance(float_, float):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': float_}\n>>> responder.add_response(response)\n>>> assert isinstance(float_, float)\n>>> assert str(float_) == out, 'float_ incorrectly implemented.'\n",
         "failure_message": "float_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "float_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_3'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6MCsq3JZUW-PsgT0me3n_J_YHZJTH90hSi8_wOMvR6V0uhdd0Z4ObqizkbE_3tl0jG1AfjgheMaEIH04ffH97vZ4Yw==')\n>>> if str(bool_) == out and isinstance(bool_, bool):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': bool_}\n>>> responder.add_response(response)\n>>> assert isinstance(bool_, bool)\n>>> assert str(bool_) == out, 'bool_ incorrectly implemented.'\n",
         "failure_message": "bool_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "bool_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_4'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6MDN40KGTUiCYSgq5JUH8h32I85QvQV1PBGYO_O4fXyVRdGaQc7nwr-iD7nqD0_W0pTUlkZahLzitwGr-WK6OHX8xA==')\n>>> if str(string_) == out and isinstance(string_, str):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': string_}\n>>> responder.add_response(response)\n>>> assert isinstance(string_, str)\n>>> assert str(string_) == out, 'string_ incorrectly implemented.'\n",
         "failure_message": "string_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "string_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_5'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6MGrPcrPs3yo-J9Ih38ykNusMWQWZhWeSmhV71lIFjMtchzRh9kdnf4KHKyfX-JA3vaWtKIwLC01YUKdl8LaWgOhZg==')\n>>> if str(list_) == out and isinstance(list_, list):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': list_}\n>>> responder.add_response(response)\n>>> assert isinstance(list_, list)\n>>> assert str(list_) == out, 'list_ incorrectly implemented.'\n",
         "failure_message": "list_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "list_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_6'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6MI7e1k8IEJ87zyTLI26Rj6eH9wPwbRLzfBfcX9uNTxcg8qDNbTg9MaLp9dQJQrnYbNQpQINpgebXFFBqMRqXFviuQ==')\n>>> if str(tuple_) == out and isinstance(tuple_, tuple):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': tuple_}\n>>> responder.add_response(response)\n>>> assert isinstance(tuple_, tuple)\n>>> assert str(tuple_) == out, 'tuple_ incorrectly implemented.'\n",
         "failure_message": "tuple_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "tuple_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responser = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_7'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABl6MLBvYi3_vYH5B5AXz4hCVykYrvuRMCd9rzFwS2TnRpgWUXYF90NG_rSBOB4nKHNGh1t8LJeGow9L25DM0AxnNLkpwRgjQyW81CBlhCEYQtIw6Y=')\n>>> if str(dict_) == out and isinstance(dict_, dict):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': dict_}\n>>> responser.add_response(response)\n>>> assert isinstance(dict_, dict)\n>>> assert str(dict_) == out, 'dict_ incorrectly implemented.'\n",
         "failure_message": "dict_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "dict_ correctly implemented."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6-Building a Stress Sensor": {
     "name": "q6-Building a Stress Sensor",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> points_ = [6, 6, 8, 8, 8]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q6_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_1'\n>>> max_score = 6\n>>> score = 0\n>>> if isinstance(StressSensor, type):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': isinstance(StressSensor, type)}\n>>> responder.add_response(response)\n>>> assert isinstance(StressSensor, type), 'The Class StressSensor is not implemented.'\n",
         "failure_message": "The Class StressSensor is not implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "The Class StressSensor is implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_2'\n>>> max_score = 6\n>>> score = 0\n>>> t = StressSensor(25000)\n>>> if hasattr(t, 'stress_pa') and t.stress_pa == 25000:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': t.stress_pa}\n>>> responder.add_response(response)\n>>> assert hasattr(t, 'stress_pa'), \"StressSensor does not have 'stress_pa' attribute\"\n>>> assert t.stress_pa == 25000, 'StressSensor initialization did not set attribute stress_pa correctly'\n",
         "failure_message": "The Class StressSensor initialization is implemented incorrectly.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "The Class StressSensor initialization is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_3'\n>>> max_score = 8\n>>> score = 0\n>>> t = StressSensor(25000)\n>>> t.set_stress(50000)\n>>> if t.stress_pa == 50000.0:\n...     score += 4\n>>> t_ = StressSensor(25000)\n>>> t_.set_stress('abc')\n>>> out = str(t_.stress_pa)\n>>> if out == 'fail':\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [t.stress_pa, t_.stress_pa]}\n>>> responder.add_response(response)\n>>> t = StressSensor(25000)\n>>> t.set_stress(50000)\n>>> assert t.stress_pa == 50000.0, 'set_stress does not function properly'\n>>> t = StressSensor(25000)\n>>> t.set_stress('abc')\n>>> out = str(t.stress_pa)\n>>> assert out == 'fail', 'set_stress does not return the correct response when a unsuitable input is provided'\n",
         "failure_message": "set_stress can not correctly handle non numeric inputs.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "set_stress can correctly handle non numeric inputs."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_4'\n>>> max_score = 8\n>>> score = 0\n>>> t = StressSensor(68947.57)\n>>> if abs(t.to_psi() - 10.0) < 0.01:\n...     score += 4\n>>> hold = t.to_psi()\n>>> t.set_stress(137895.14)\n>>> if abs(t.to_psi() - 20.0) < 0.01:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [hold, t.to_psi()]}\n>>> responder.add_response(response)\n>>> t = StressSensor(68947.57)\n>>> assert abs(t.to_psi() - 10.0) < 0.01, 'Incorrect conversion to psi.'\n>>> t.set_stress(137895.14)\n>>> assert abs(t.to_psi() - 20.0) < 0.01, 'Incorrect conversion to psi.'\n",
         "failure_message": "Incorrect conversion to psi.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "Correct conversion to psi."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> import json\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_5'\n>>> max_score = 8\n>>> score = 0\n>>> stress_sensor = StressSensor(68947.57)\n>>> stress_pa = stress_sensor.stress_pa\n>>> stress_psi = stress_sensor.to_psi()\n>>> conditions = [hasattr(stress_sensor, 'stress_pa'), hasattr(stress_sensor, 'to_psi'), stress_pa == 68947.57, abs(stress_psi - 10.0) < 0.01]\n>>> statements = [\"StressSensor does not have 'stress_pa' attribute\", \"StressSensor does not have 'to_psi' method\", 'Incorrect stress value for stress_pa.', 'Incorrect conversion value for stress_psi.']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': conditions}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "Incorrect conversion to psi.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "Correct conversion to psi."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7-Determining a Price of a Structural Beam": {
     "name": "q7-Determining a Price of a Structural Beam",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> points_ = [0, 1, 0, 6, 15, 12, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q7_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_1'\n>>> max_score = 0\n>>> score = 0\n>>> conditions = [material_cost['Steel Beam'] == 250, material_cost['Aluminum Beam'] == 150, material_cost['Reinforcement Bar'] == 50, material_cost['Concrete Mix'] == 120]\n>>> statements = ['Steel Beam not correctly defined', 'Aluminum Beam not correctly defined', 'Reinforcement Bar not correctly defined', 'Concrete Mix not correctly defined']\n>>> for condition in conditions:\n...     if condition:\n...         score += 0\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': conditions}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "material_cost is incorrect. Please make sure you did not modify the dictionary.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "material_cost is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import json\n>>> responser = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_2'\n>>> max_score = 1\n>>> score = 0\n>>> if np.__version__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': np.__version__}\n>>> responser.add_response(response)\n>>> assert np.__version__ is not None, 'numpy is incorrectly imported'\n",
         "failure_message": "numpy incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "numpy correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_3'\n>>> max_score = 0\n>>> score = 0\n>>> conditions = [beam_requirements['Steel Beam']['quantity'] == 10, beam_requirements['Concrete Mix']['quantity'] == 3, beam_requirements['Reinforcement Bar']['quantity'] == 7, beam_requirements['Custom Alloy Beam']['quantity'] == 2, beam_requirements['Custom Alloy Beam']['price'] == 1200]\n>>> statements = ['Steel Beam quantity not correctly defined', 'Concrete Mix quantity not correctly defined', 'Reinforcement Bar quantity not correctly defined', 'Custom Alloy Beam quantity not correctly defined', 'Custom Alloy Beam price not correctly defined']\n>>> for condition in conditions:\n...     if condition:\n...         score += 0\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': conditions}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "beam_requirements is incorrect. Please make sure you did not modify the dictionary.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "beam_requirements is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_4'\n>>> max_score = 6\n>>> score = 0\n>>> conditions = [price_calculator.__name__ == 'price_calculator', price_calculator.__code__.co_argcount == 3]\n>>> statements = ['Function name is incorrect. It should be price_calculator.', 'The price_calculator function does not have the correct number of arguments (expected: material_cost, beam_requirements, profit).']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [price_calculator.__name__, price_calculator.__code__.co_argcount]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "price_calculator call is incorrect. Ensure function name, arguments, and calculation logic are correct for structural beams.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "price_calculator call is correct for structural beam price estimation."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_5'\n>>> max_score = 15\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6MvajDvDxG6mf-GXt8a7PK8yxNRY5RvjDyB-Uhi2Pe1QxOTDks-IcS0NlqA8QRtVEvN-mDzPusk5IyJa5Mr70LqFeQ==')\n...     if str(price_calculator(material_cost, beam_requirements, 0.2)) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': out}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert str(price_calculator(material_cost, beam_requirements, 0.2)) == out, 'price_calculator  computation is incorrect.'\n",
         "failure_message": "price_calculator computation is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 15,
         "success_message": "price_calculator computation is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_6'\n>>> max_score = 12\n>>> score = 0\n>>> parts_2 = material_cost.copy()\n>>> parts_2['Steel Beam'] = 10\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6MxU5vtTWbI4SgDP6bof8xgVvoiD7kLugrfSyWriqXlSa729QyUzs_Wa-cDOzS28ueLXLnV7ACX7aj_2MLu7kILdXw==')\n...     if out == str(price_calculator(parts_2, beam_requirements, 0.2)):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': out}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert out == str(price_calculator(parts_2, beam_requirements, 0.2)), 'Your code does not use the beam_requirements correctly'\n",
         "failure_message": "Your code does not use the material_cost correctly.",
         "hidden": false,
         "locked": false,
         "points": 12,
         "success_message": "Your code correctly uses the material_cost."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_7'\n>>> max_score = 6\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6Mznzrh3BqQgYjsfq_nggPhmz1ZkwL6rN_bNPRbdjazndqzFxOzzEV0AkkXvCh_PCxxc5rH2cMCo_wpbE7rXOnAwz7xiFWfpenZTeG4kchmdnQoNH0RJ9m2CLx1IpCqfGoJl')\n...     if print_total(price_calculator(material_cost, beam_requirements, profit)) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': out}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert print_total(price_calculator(material_cost, beam_requirements, profit)) == out, 'The string being printed is not correct'\n",
         "failure_message": "print message is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "print message is correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8-Plotting and Fitting": {
     "name": "q8-Plotting and Fitting",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> points_ = [2, 6, 4, 2, 3, 6, 2, 2, 2, 2, 2, 4, 4]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q8_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_1'\n>>> max_score = 2\n>>> score = 0\n>>> conditions = [np.__name__ == 'numpy', plt.__name__ == 'matplotlib.pyplot', 'curve_fit' in dir()]\n>>> statements = ['numpy not imported correctly', 'matplotlib.pyplot not imported correctly', 'scipy.optimize.curve_fit not imported correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2 / len(conditions)\n>>> score = int(round(score, 0))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': plt.__name__}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "Your input statements are incorrect.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Your input statements are correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_2'\n>>> max_score = 6\n>>> score = 0\n>>> x_test = np.array([0, 1, 2])\n>>> (a_test, b_test, c_test) = (1, 1, 1)\n>>> expected_output = np.array([0.84147098, 0.90929743, 0.14112001])\n>>> conditions = [np.allclose(sinusoidal(x_test, a_test, b_test, c_test), expected_output)]\n>>> statements = ['sinusoidal function is not implemented correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 6\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [*sinusoidal(x_test, a_test, b_test, c_test)]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "sinusoidal function is not implemented correctly",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "sinusoidal function is implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_3'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [np.allclose(x_data[0], -np.pi), np.allclose(x_data[-1], np.pi), len(x_data) == 100, np.isclose(sum(x_data[3::3]), 3.141592653589801)]\n>>> statements = ['x_data is not defined correctly', 'x_data is not defined correctly', 'x_data length is not correct', 'x_data is not defined correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "x_data is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "x_data is defined correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_4'\n>>> max_score = 2\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6OsbZQjh0i9RMNKzHdS3XHchdX1y11dJFaOJUR2JCtIEHeL1Z1T1EzXG8R6Rh2FFBE6DueCEeQ-E9F5ZJHHQoXTSVZyfQGTjuHFUS4z9-i7v5RKOV08uYnuw_ILTI4DuWg-CvTfjp-DlQ22FPcSC9EBpcL_j8yAVh0qmS-yoKsCeldw9-XjW-YhvLDDImhz5bQRMXEMHzcL5cIkGcj3fKz2UwU2A9-uaj6ywdF1bFPCwF69PH8B9laY7h1f9DnBSbecDKgS1W7z8RwOmzgXfGoEDaQ8sVx8LjG2tgRVGY1D2dqeta1pU2TG1yeocOUflXlOCjnPidrnskGoiOQgpb08B6AFi81yjpzOCzokz261V_-wycXTcpEA8SXeDf9NxXtTpo66Bty6qZR49uuNchQFMts6AS8OypsXEI00CwDUAduRdr7VTlLWSbAjHICNu1tsM09jUvcz9-VjIlfv5lMD2U0uMqh-8X9n-jjg6ia8ZJbXSl_tSCGRYFjd50zsCTLBGVBVSo4BwQPL3UE5xLSUZdGKBxXtadw89Gz8IU5HXklkmbagG2phVABCLi-5nUrd30u-Q3CZXzV3ftig2SvTjzD6Rq9maIJAB5tpUDPaEUZRx08z4XK0b0KbbTseRqnN4atU8rQpwLSrcWtdxCYJ2e3TBSAmYV075VV3OAef7R-j1dN_ZYdKlcL3VA7GMtMjfZqfigGycG1Yj8vWpTgLuRgplHhgnkPSrciCwt9-EeDzGl76zBYd-j3veme-CaHhTxLWDUwauDHtMBy745xd9BQYiS6PcofHxVc0nygk39M5nMGIBeZqaNAqmovkQlIBAw92dFu-psEWPZxdJEpKuSurFJ-KWRvt3QUvHG4rvnM3IZAR4hqaC94-1RVL0L8LxtL7LY1Gun7RoyLDvRBNjVNcUqQT4YyyW0S9iiVoaJGCY-KMUp4A_fu-w2AcBuIg56l3KBjpxJRTROM_T122Vnaq7F_mLFycn3k6ruzt3uGJDRSXrvwAWPF_Mw1hxVDTobimaRuadpRbkLbtZAnxo1UqQ5c8zaCRBfTa6EWk-C7taKWRsqW-s_XB_DFgLMoJkasX7_8GstKCaEzY6SDXrrLNQ2V2WTHpPKzxjIZ8mrvty0F7a5S8rkvi-aWkFQmvuUesnyy7XKI2uAb-Jx97LBKkjWm9IHzcwh5B5B1r0mbaMfzB2PI15bBuesN-stCbbpvGgtSanvYTZ6ERik-uwK-NXUD1F2yK2dGQ0j2JlMTkXzW2dt4vZCEBLKd5-TmMkikLGU1PsLxIOjbgTDxW82WDl2CqIqARb2A8B-HneUT4sDvSmGylS7Z3_04rR5BnBX18kWWkdldsJWzjRTEMrVTCIxPSCLh1Y7v2_bUgZPJIqQlqw5hNwx4MYsmA2DigY45S5gYU1rXMVqvWUxr0lD-4RBtyL13KsOCMo8LcdbIWWTA4t0ur9UXnj2wY4FPoxub1BIEEi6gRcuQtbDdwG1ITcEdOSwkAn-dPWmc_kz88q71qLO5uydMAS9jCp_54n6M_2yudBeQQpGJT0lCklMtHD2XS0vADLxiyyd-2lC8QiPVECCTV2q8jSqTF0RPqg8Mx-MgEso0I2GDy4RXDJLTk3m3_IQYrLI9_jnV8lvLHfAaQ_YI8ZNUl4SPGvi8KPeWKgkefLwl2ZL1cp6Sw9hA==')\n...     if str(y_true) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(y_true)}\n>>> responder.add_response(response)\n>>> assert str(y_true) == out, 'y_true is incorrect'\n",
         "failure_message": "y_true is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "y_true is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_5'\n>>> max_score = 3\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6OtEtOwzVaFP-LljEIHyP6-mr8OoF-fGBwX_Q3Sm4eFERLQQ-AyW0gLo2TNEB9fRZ3tpgddE8mlqGKFB-GLzHe0cEBiN_W-uSQzEpmfDL7uveLymqlJer8hz7ew0hZp1K5a2pjgSkEcroiLK5GE8aAmYGxpBTQ0aFV-6J5R1Dlr5siVApd-uYr_YEcDf2J7apeQAzO5cTz-shlM8u-aULYV8FFFf0AQt3kftySGKm2eEE2OlDJ3H9e6tvS3AaFbOpqos7DX1IJG3wTjiCEgI07oXMYBsObyerWtaxQCYp3TC_X3zfr4p1qiDxIHeTlrSgr8SinpS_pct8eidsO71J2HOAvRG_oJuDhUNqrm7bXzhA7mg0piB0LeeBmFH_jglzKXmX_sO3v_ixqvmEg5hUgrHxYulAcg_WhWNQp_fNiM9oXIjFdEKDZEvGjlOoQi3J2UTvKDc9UM1NDJRTftUeWOa6tatH9vmNMKUQgpT-xxiYB-a20038iSSMBna-rf8K5Pfz5YUwlCIuvsQoPPmgC-nosrs76lbSoau6XuHYPcBQNvnjK2OdKtGpDQbfcwnwRACIiWZIXjGDMLv7p9nxnEG4pZwFrQRoL470IkEM5qsCL_ZVd9lh3Qtn9Nr0qJLKbTD8nYJIkR0UpNNhMapbWJOpg9blozNkHASkvkR4bJjtuQRIwUE4pCknwjg8XkrgX1aw2tjQf_niSmVA25nAH5V-JCBHe2ZBRSDBiJb1Hw2Mhj8-2y38umnP_to_FYT3tIdTv5kstwxQ6UhgtWmYTMiZVee87WRQLuIjDSpDPPdwaUbwOmQyvdJ_WAbZCvMjI37U-RtR80yu86g7_Ss-YY0mj9z2GtsqKoxZmR51UztX91jHmPGJwrMLVN4655l1BtVG9DrOPiC_zldoFDEDhbC4WHfnb555hux7CDm_b3yh-PDmIdoJ6i9UBtTY-OJ9I7VpjqBg3mxAKFHDT2J52np30qoCAaHs_uBLv7xx3_BPFDEDgwsHlMkk0M3Nih6u0QeV3JQAFEjghpc_i1eJ4wTCHAUbTb3PIdmcROir7EwDCnewNOW9FtU5dTZnSESHzNgCt5i5b6UR7YVXuVqeEh3-I1BkUbSrXbVcHUoAkqnVYaqANS_hkkVPw9Cj85thgHM7ne2zGSozzREyztW6JUkf0Ew8LUKe3R6B5VJjpQxRIO87QiMHEG8AHKkbJFPhtcO3FeEClsVuLV7pMFVieC2ORe32dfqNtkSxx9cwtejS5FUsjfXWaaA_wJciF8eZBhBUHzoX0k-kKednL8afCva1UWVeom0PwCoBGe-lz5ES3quPKK1WW-kIDukrnxj2qkwTmbi47YrQ2BJaMB4xVw3Zb7PQMAmlk4QqDtDDdlsvwlii6e3i7ryYNBdmDfsDITdVCDl252STmbsMbDihdH9O_qzHm5mvyS8qq1FrFwnq30rl-kvpuXnjeX4hb1TKQTsX10tm3-3ltbTJIFl0tkS-7b3eLvdZJYCvu4Wb3aa_v_F9ifBVBaskjrSW4yr-bM1cnT6yK9NUA8xVZhS7TedLDY1xwhFNqqEQPWOrdZKIBUeDYXwlJziCpG8Zf3uYPsVRh92iGvwm_o8KabdHnE_BTMj6oWmAO-7HNdWr-zPAyCL5ZedCPn6rSkc7bPKcA_i6M_veZG9yF4UtSVnP_EQCw==')\n...     if str(y_noisy) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': len(y_noisy)}\n>>> responder.add_response(response)\n>>> assert str(y_noisy) == out, 'y_noisy is incorrect'\n",
         "failure_message": "y_noisy is not implmemented correctly",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "y_noisy is implmemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_6'\n>>> max_score = 6\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6OuLOJTIDo4-g5gul9bHne9fZvoqMC-aRLfGuaW5jufR6c40uhOv9YNIdn3AJ4qaC8ep1fulysL5rCF57gj6wtHC76yB2ULQsk_xANFzO11m9iTI1Q5mBeO0oNmchIlV2_R_')\n...     chars_to_remove = ['[', ']', '\\n']\n...     for char in chars_to_remove:\n...         out = out.replace(char, '')\n...     out = [float(x) for x in out.split(' ')]\n...     if np.allclose(popt, out):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [*popt]}\n>>> responder.add_response(response)\n>>> assert np.allclose(popt, out), 'popt is not returning the correct values'\n",
         "failure_message": "popt is not returning the correct values",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "popt is returning the correct values"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_7'\n>>> max_score = 2\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABl6OwH26bBtouW6OVlhUW0_kJ_k74V6vgjdhX7MgLzuxFAg8fJQGpd7zsHjOvmWM4ECLY1xAsyoQiGwShs8V9VHdZ9RjNLVEW3AkDSOye_fZOH4aOAEBvR_3R4vCYKRe0Q20jOO4KXmxQgJLg4_RiDM7j-m3LBAlERZRMlOF_Z9iYH2lZfX007jtizGFpmoorfn8Waa0xYTBCUmQ2OWT1tiTDfFdAZTkLERFeS4KFe7pcJ_mPAdSQJNUJ7jgbgR_zlEK-Bc8jeoVqsl1pZ23b1HD0VQykIs-dUydIjhZ3E7gTX0bNAHDNKU0t6U8qcYgtopBG9WnT4r8iGCJzmsVc-022XbV54eTuD2g5LTRC53GBMsNtarA91W-yu8uYWqNc7CcRJzbugLYcduDA7ez0KDuitaEbAA0H666ssYKTuoQ3YYBbLNDv0HDOY74X8EkQlBPPn1LNzXmVfbPCt4eOPInnREaDejmWnrHIqaCtGfcDS0YStN9PiTWU-HELMXDOZb0bFi1RGFZgjWXcIqZ6ggjkYU93Zxy03ZMvyHDoDNfc99oH9TBgefk7alU0EiQfrfwvzVRtJH9yuhP0Qfubuh2YFJw4j1vBtZflJvAP0azpb_pFUBMaoFXbmx8-XSITba1cDYoHl0V4knDiRXQiFNxe3-hQJX_JJJyCGIs7UPqaeSrbl77yYJQ33GcN5xHuTZbPibHTCzE10tTistmOYp3lVCHsxujiW5708h-yf7M-0u1ZPiixd5d0cfaZXmyRCrxGNb3Bvfm7Tfip-_PRzp8Coycj_vtm6uHX-xkfaoPzm6RqV-y1LBn_EdmeXL4AqKbuZ-HpcJbkgn7vd5XiGHZ6nAjnDBd58rT8uJIDDA50RLWw0xmkKHPOlmwB6a_7_iWV1MKW2620vBkikECIfamdWcnNUNT3aFVbl7TNsTF8r2k70YjyQTo4Pffl3CoVNC2eIXGBPgGTs0NLHOtq1XmKgrI-0lvBO__c2Qr72M1wa2mqqYjjcrHz5j5ZwzBKH3ayI4rvDfzrqAuBLyT0kkfwQt1H1wGbD82bt7ya3ZGYcJ-o62U4pFrsuKt2OyZUcTnG13tZycS9nGS_CRIhOJxy5gygU684TRecF5l0t1OWx0WNPWpv82EM_C6vAIasip2zVYmpuYgwDb_j7WWpFzSywjvJYU0F52Sow1QYJqkORIY5yKF88fxo6oudaLvykU96-SJE3jMMol_Wf9wQXxIGQkmEagjHuqXzN3gYgs1X1rkzbtJZJXH8wl_w7g-eHJZ_OwFldugolbJtGFBna2aFvPpteQl-v2rhClqGqZbLDOu3wIMEoF2ggC3VSx-bYKKh5J8jtc7oV-l5lFrUqHMzB3SRCe8pwAv6Dv7ptj6efOcUBKdTQ68t08WMTsKN-CEtUPhb6ZUnHGcI9Pr8mUTvAr6WyKzNMNIdFbqnwlQV1UolvunpesbItk6gtLeYcvfQ58bdGHjsn0Gbrq1U71P1F0qy_wiVX_brtXb2zXmcKBZalUgIU_BTHjEMkeTBcG01wllqOqBpwLlo2_AH10CDV0KcBU2HJU4BfaHot884O6m6nx9LY4WYkLuvXYDKpKB5WBi154v1U_BINtTjryQocGxZLpgy8m5kB3vFugCIcPk8OWUcnUqu_msPNBo1KFbxYx7M921j_aTE6uc796yoSUy9IxJ-4EveGigFD2E4hIAc=')\n...     chars_to_remove = ['[', ']', '\\n']\n...     for char in chars_to_remove:\n...         out = out.replace(char, '')\n...     out = out.replace('  ', ' ')\n...     out = [x for x in out.split(' ')]\n...     out = [item for item in out if item != '']\n...     out = [float(x) for x in out]\n...     if np.allclose(y_fit, out):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [*popt]}\n>>> responder.add_response(response)\n>>> assert np.allclose(y_fit, out), 'y_fit is returning incorrect values'\n",
         "failure_message": "y_fit is returning incorrect values",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "y_fit is returning correct values"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_8'\n>>> max_score = 2\n>>> score = 0\n>>> conditions = [plot_1.axes.get_xlabel() == 'x', plot_1.axes.get_ylabel() == 'y']\n>>> statements = ['xlabel is incorrect', 'ylabel is incorrect']\n>>> for condition in conditions:\n...     if condition:\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [plot_1.axes.get_xlabel(), plot_1.axes.get_ylabel()]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "The plot labels are incorrect.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The plot labels are correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_9'\n>>> max_score = 2\n>>> score = 0\n>>> conditions = [plot_1.get_label() == 'Noisy Data', plot_2[0].get_label() == 'Fitted Sinusoidal']\n>>> statements = ['Noisy Data', 'plot_1 is not labeled correctly', 'Fitted Sinusoidal', 'plot_2 is not labeled correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += max_score / len(conditions)\n>>> score = int(round(score, 0))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [plot_1.get_label(), plot_2[0].get_label()]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "the plots are not labeled correctly",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "the plots are labeled correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_10'\n>>> max_score = 2\n>>> score = 0\n>>> conditions = [plot_2[0].get_color() == (0.0, 0.5, 0.0, 1) or plot_2[0].get_color() == 'g' or plot_2[0].get_color() == 'green']\n>>> statements = ['Fitted Sinusoidal fit is not the correct color']\n>>> for condition in conditions:\n...     if condition:\n...         score += max_score / len(conditions)\n>>> score = int(round(score, 0))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [plot_2[0].get_color()]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "Fitted Sinusoidal fit is not the correct color",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Fitted Sinusoidal fit is the correct color"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_11'\n>>> max_score = 2\n>>> score = 0\n>>> conditions = [plot_1.axes.get_legend() is not None]\n>>> statements = ['The legend is not correct on the plot']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': [plot_1.axes.get_legend() is not None]}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "The legend is not correct on the plot",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The legend is correct on the plot"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_12'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [all(plot_2[0].get_xdata() == x_data), all(plot_2[0].get_ydata() == y_fit)]\n>>> statements = ['the x data for plot_2 is not correct', 'the y data for plot_2 is not correct']\n>>> for condition in conditions:\n...     if condition:\n...         score += max_score / len(conditions)\n>>> score = int(round(score, 0))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': conditions}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "plot_2 does not have the correct values.",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "plot_2 is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import responses\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_13'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [np.array_equal(plot_1.get_offsets()[:, 1], y_noisy), np.array_equal(plot_1.get_offsets()[:, 0], x_data)]\n>>> statements = ['the y data for plot_1 is not correct', 'the x data for plot_1 is not correct']\n>>> for condition in conditions:\n...     if condition:\n...         score += max_score / len(conditions)\n>>> score = int(round(score, 0))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': conditions}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "plot_1 does not have the correct values.",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "plot_1 is correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d7d046052154998ca7dd3d9af52f7220fee50748c9a05b256540159ca8eb430c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
